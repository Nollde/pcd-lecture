{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93c2f0ba",
   "metadata": {},
   "source": [
    "# Ratio with a DNN\n",
    "\n",
    "In this task we will explore the method of measuring ratios of distributions with DNN driven classifications.\n",
    "\n",
    "## Introduction\n",
    "We will create data from two Gaussian distributions and measure the ratio of the underlying probability functions in three ways:\n",
    "- Analytic (only possible in the toy experiment)\n",
    "- Classic (bin and measure the ratio in each bin)\n",
    "- Classification (train a DNN to classify between the two datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20329dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4f97e5",
   "metadata": {},
   "source": [
    "## Creating and plotting the data\n",
    "First we fix the parametrisation of our Gaussian distributions (A and B) and create the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametrisation of the underlying probability distributions\n",
    "loc_a, scale_a = -0.5, 1.0\n",
    "loc_b, scale_b = 0.5, 1.0\n",
    "\n",
    "# creating the data\n",
    "a = np.random.normal(loc=loc_a, scale=scale_a, size=(100000,))\n",
    "b = np.random.normal(loc=loc_b, scale=scale_b, size=(100000,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2890ec5b",
   "metadata": {},
   "source": [
    "We bin the data in histograms with equidistant bins, plot the histograms and plot (parts of) the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the figure\n",
    "fig = plt.figure()\n",
    "gs = fig.add_gridspec(2, 1, hspace=0, height_ratios=[3, 1])\n",
    "(ax1, ax2) = gs.subplots(sharex='col')\n",
    "\n",
    "# plot histograms\n",
    "hist_a, bins_a, _ = ax1.hist(a, bins=np.arange(-4, 4.4, 0.4), alpha=0.5, label=\"Distribution A\")\n",
    "hist_b, bins_b, _ = ax1.hist(b, bins=bins_a, alpha=0.5, label=\"Distribution B\")\n",
    "\n",
    "# plot 1000 example points\n",
    "ax2.plot(a[:1000], np.zeros_like(a)[:1000], linestyle=\"None\", marker=\"|\", alpha=0.1)\n",
    "ax2.plot(b[:1000], np.zeros_like(b)[:1000], linestyle=\"None\", marker=\"|\", alpha=0.1)\n",
    "\n",
    "# styling plot\n",
    "ax2.axes.get_yaxis().set_visible(False)\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"Counts [#]\")\n",
    "ax2.set_xlim([-4, 4])\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ecea0",
   "metadata": {},
   "source": [
    "## DNN based Classification\n",
    "\n",
    "Now create a DNN model for the classification between Distribution A and Distribution B.\n",
    "- How many inputs do we have?\n",
    "- How many outputs do we have?\n",
    "- How many layers with which activation funcitons do we need?\n",
    "- Does the network output probabilities or logits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbbc75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "# TODO\n",
    "model = tf.keras.Sequential(\n",
    "    layers=[\n",
    "        tf.keras.Input(shape=(1,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131b396",
   "metadata": {},
   "source": [
    "Now compile the model.\n",
    "- Which loss function do we want?\n",
    "- Which optimizer do we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52114d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "optimizer = None  # TODO\n",
    "loss = None  # TODO\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8dee9",
   "metadata": {},
   "source": [
    "Look at the model summary to see how many trainable parameters or model has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cd8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664744b9",
   "metadata": {},
   "source": [
    "Now we prepare the data for the training by interleaving datasets A and B and shuffling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47253403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data for training (interleave+shuffle)\n",
    "x = np.concatenate([a, b])\n",
    "y = np.concatenate([np.ones_like(a), np.zeros_like(b)])\n",
    "p = np.random.permutation(len(x))\n",
    "x, y = x[p], y[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85757895",
   "metadata": {},
   "source": [
    "Now we fit the model to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013e12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(x=x, y=y, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e4e01b",
   "metadata": {},
   "source": [
    "## Plotting and Results\n",
    "In the following cells we will measure the ratio in the above mentioned three ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x_values for inference and plotting\n",
    "x_values = np.arange(-4, 4.01, 0.01)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160928b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analytic solution\n",
    "def gaussian(x, loc, scale):\n",
    "    return 1 / np.sqrt(2 * np.pi * scale ** 2) * np.exp(-((x - loc) ** 2) / (2 * scale ** 2))\n",
    "\n",
    "analytic_ratio = gaussian(x_values, loc=loc_a, scale=scale_a) / gaussian(x_values, loc=loc_b, scale=scale_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b85be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classic solution by histogram division\n",
    "hist_ratio = hist_a / hist_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dfc3af",
   "metadata": {},
   "source": [
    "Think about how to transform the network predictions into the ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN based classification solution\n",
    "pred = model.predict(x_values)\n",
    "pred_ratio = None  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86373833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the infered ratios\n",
    "plt.plot(x_values, analytic_ratio, label=\"Analytic\", color=\"black\", linestyle=\"--\")\n",
    "plt.step(bins_a, np.pad(hist_ratio, (1, 0), 'edge'), label=\"Histogram Division\")\n",
    "plt.plot(x_values, pred_ratio, label=\"DNN Based Classification\", color=\"red\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Ratio A/B\")\n",
    "plt.xlim([-4, 4])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0742090c",
   "metadata": {},
   "source": [
    "As you can see, the DNN scale factor has central improvements compared to the histogram division:\n",
    "- It is continuous over the whole range\n",
    "- It does not suffer so much from insuficient statistics (towards the edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e916c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This concludes our tutorial for today.\n",
    "\n",
    "In this tutorial you learned:\n",
    "- How to measure the ratio of probability distributions:\n",
    "  - Analytic (only possible in a toy experiment with known probability distributions)\n",
    "  - Classic (binning and measuring the ratio in each bin)\n",
    "  - By a DNN driven classification between the distributions\n",
    "- Why the DNN diven classification approach is favourable compared to the classic approach:\n",
    "  - Continuous\n",
    "  - Works with low statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42625de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
